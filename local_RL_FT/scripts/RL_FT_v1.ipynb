{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7955226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0 - Create a new conda environment and install dependencies\n",
    "# conda create -n rl_ft_gpu python=3.11 -y\n",
    "# conda activate rl_ft_gpu\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "# pip install transformers==4.44.2 datasets accelerate trl==0.9.6 sentencepiece\n",
    "# pip install scikit-learn wandb jupyter notebook\n",
    "# python -m ipykernel install --user --name=rl_ft_gpu --display-name \"RL Finetune (GPU)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dc62244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME: C:\\Program Files\\Eclipse Adoptium\\jdk-21.0.8.9-hotspot\n",
      "PATH: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.9\\libnvvp;;C:\\Program Files\\Microsoft SDKs\\Azure\\CLI2\\wbin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\NVIDIA Corporation\\NVIDIA app\\NvDLISR;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\LINQPad8;C:\\Program Files\\dotnet\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files\\Microsoft Service Fabric\\bin\\Fabric\\Fabric.Code;C:\\Program Files\\Microsoft SDKs\\Service Fabric\\Tools\\ServiceFabricLocalClusterManager;C:\\Program Files\\nodejs\\;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2025.3.0\\;C:\\Program Files\\Git\\cmd;C:\\Program Files\\CMake\\bin;C:\\Users\\moidhassan\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\moidhassan\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\Library\\bin;C:\\Users\\moidhassan\\AppData\\Local\\anaconda3;C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\Library;C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\Scripts;C:\\Users\\moidhassan\\.dotnet\\tools;C:\\Users\\moidhassan\\AppData\\Roaming\\npm;C:\\Program Files\\Microsoft SDKs\\Azure\\CLI2\\wbin;;C:\\Program Files\\Eclipse Adoptium\\jdk-21.0.8.9-hotspot\\bin\n",
      "Torch version: 2.5.1+cu121\n",
      "CUDA version: 12.1\n",
      "CUDA available: True\n",
      "Device name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Memory allocated: 0.0 MB\n",
      "Memory reserved: 0.0 MB\n",
      "\n",
      "Transformers version: 4.44.2\n",
      "TRL version: 0.9.6\n",
      "Datasets version: 4.3.0\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üìò Step 1 ‚Äî Environment Setup & GPU Check\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\\\Program Files\\\\Eclipse Adoptium\\\\jdk-21.0.8.9-hotspot\"\n",
    "os.environ[\"PATH\"] += os.pathsep + os.path.join(os.environ[\"JAVA_HOME\"], \"bin\")\n",
    "print(\"JAVA_HOME:\", os.environ.get(\"JAVA_HOME\"))\n",
    "print(\"PATH:\", os.environ.get(\"PATH\"))\n",
    "\n",
    "# Print environment info\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Memory allocated:\", round(torch.cuda.memory_allocated(0)/1024**2, 1), \"MB\")\n",
    "    print(\"Memory reserved:\", round(torch.cuda.memory_reserved(0)/1024**2, 1), \"MB\")\n",
    "else:\n",
    "    print(\"‚ùå CUDA not available ‚Äî check environment\")\n",
    "\n",
    "# Make sure transformers & TRL are importable\n",
    "import transformers\n",
    "import datasets\n",
    "import trl\n",
    "\n",
    "print(\"\\nTransformers version:\", transformers.__version__)\n",
    "print(\"TRL version:\", trl.__version__)\n",
    "print(\"Datasets version:\", datasets.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4cb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìò Cell 2A ‚Äî Load & Prepare Synthetic Seller Email Dataset (Simple List)\n",
    "# ============================================\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_seller_emails(file_path=\"data/seller_emails.json\"):\n",
    "    \"\"\"\n",
    "    Load the synthetic seller emails dataset where each element is a full email body (string).\n",
    "    Example:\n",
    "        [\n",
    "            \"Hi John, I wanted to share some details about our new Surface lineup...\",\n",
    "            \"Dear Priya, our latest enterprise offers might interest your company...\"\n",
    "        ]\n",
    "    Returns a pandas DataFrame with one column: email_text\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"‚ùå File not found: {file_path}\")\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"‚ùå Expected JSON to be a list of email strings.\")\n",
    "    if not all(isinstance(e, str) for e in data):\n",
    "        raise ValueError(\"‚ùå Each element in the JSON list must be a string (email body).\")\n",
    "\n",
    "    df = pd.DataFrame({\"email_text\": data})\n",
    "    df.loc[:,\"len_email_text\"] = df[\"email_text\"].str.len()\n",
    "\n",
    "    # Clean and normalize text\n",
    "    df[\"email_text\"] = df[\"email_text\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    df = df.drop_duplicates(subset=[\"email_text\"]).reset_index(drop=True)\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(df)} seller emails from {file_path}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_cleaned_dataset(df, output_path=\"data/seller_emails_clean.csv\"):\n",
    "    \"\"\"\n",
    "    Save the cleaned dataset to CSV for use in fine-tuning.\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"üìÅ Cleaned dataset saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14dd32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 38 seller emails from data/seller_emails_v3.json\n",
      "üìÅ Cleaned dataset saved at: data/seller_emails_clean.csv\n",
      "\n",
      "‚úÖ Sample Cleaned Emails:\n",
      "\n",
      "--- Email #1 ---\n",
      "Biodegradable packaging: lower footprint, same cost. Talk?\n",
      "\n",
      "--- Email #2 ---\n",
      "Dear HR Director, I'm Jennifer from HealthFirst Wellness, and I wanted to share an opportunity that could significantly impact your employee satisfaction and retention. Our corporate wellness programs have helped over 200 companies reduce healthcare costs by an average of $450 per employee annually while boosting morale. Can we schedule a brief demo to show you how easy implementation can be? Warm regards, Jennifer Park Corporate Wellness Consultant HealthFirst Wellness\n",
      "\n",
      "--- Email #3 ---\n",
      "Learning platform lifts test scores 18%. Pilot?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üìò Step 2B ‚Äî Execute & Inspect Synthetic Seller Dataset\n",
    "# ============================================\n",
    "DATA_PATH = \"data/seller_emails_v3.json\"\n",
    "OUTPUT_PATH = \"data/seller_emails_clean.csv\"\n",
    "\n",
    "df_seller = load_seller_emails(DATA_PATH)\n",
    "save_cleaned_dataset(df_seller, OUTPUT_PATH)\n",
    "\n",
    "print(\"\\n‚úÖ Sample Cleaned Emails:\\n\")\n",
    "for i in range(min(3, len(df_seller))):\n",
    "    print(f\"--- Email #{i+1} ---\")\n",
    "    print(df_seller.iloc[i][\"email_text\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbcc22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_text</th>\n",
       "      <th>len_email_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biodegradable packaging: lower footprint, same...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear HR Director, I'm Jennifer from HealthFirs...</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning platform lifts test scores 18%. Pilot?</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, I work with boutique hotels to enhance ...</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cut cloud spend 30‚Äì40%. 15‚Äëmin chat next week?...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hello, I'm Jake from RetailAnalytics Plus, and...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistics costs down 20‚Äì30%. Explore fulfillment?</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hi, I'm reaching out from DataSync Solutions b...</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dental no‚Äëshows down 40%, throughput up 15%. D...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Good morning, As consumers increasingly prefer...</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wellness saves $450/employee yearly. Quick demo?</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hello, I'm Marcus from AutoFleet Management, a...</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zero‚Äëcapex solar: ROI 4‚Äì5 yrs, big carbon cuts...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hi, We optimize e-commerce shipping and fulfil...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Organic produce &lt;24h from harvest. Sample box?</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hi, BuildPro reduces project delays by 35% thr...</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Predictive maintenance: 25% less downtime in 6...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hi, Saw your LinkedIn campaign. Our AI ad plat...</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Influencer matching: 5√ó engagement at 60% lowe...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dear Legal Operations Manager, I'm reaching ou...</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hotel tech boosts reviews +23%. 15‚Äëmin intro?</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hello, Our predictive maintenance systems redu...</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AI ads: 3‚Äì4x ROAS for brands like yours. Case ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Good morning, Our interactive learning platfor...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Free ransomware security audit for financial o...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Dear Practice Manager, I'm reaching out from M...</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Contract review 60% faster with AI. Extended t...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Good afternoon, Our regulatory compliance soft...</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Retail foot traffic analytics lift conversions...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hi, Our integrated tenant portal reduces maint...</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Quote time: hours ‚Üí minutes for agencies. Expl...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Tenant portal halves maintenance response time...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Dear Chief Marketing Officer, I noticed your b...</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fleet telematics can save ‚âà$85K annually. Brie...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Compliance software trims FDA timelines 20%. L...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BuildPro cuts delays 35% via real‚Äëtime schedul...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hello, With the recent increase in ransomware ...</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Hi, GreenEnergy Solutions offers industrial so...</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           email_text  len_email_text\n",
       "0   Biodegradable packaging: lower footprint, same...              58\n",
       "1   Dear HR Director, I'm Jennifer from HealthFirs...             478\n",
       "2     Learning platform lifts test scores 18%. Pilot?              47\n",
       "3   Hello, I work with boutique hotels to enhance ...             432\n",
       "4   Cut cloud spend 30‚Äì40%. 15‚Äëmin chat next week?...              57\n",
       "5   Hello, I'm Jake from RetailAnalytics Plus, and...             436\n",
       "6   Logistics costs down 20‚Äì30%. Explore fulfillment?              49\n",
       "7   Hi, I'm reaching out from DataSync Solutions b...             427\n",
       "8   Dental no‚Äëshows down 40%, throughput up 15%. D...              50\n",
       "9   Good morning, As consumers increasingly prefer...             478\n",
       "10   Wellness saves $450/employee yearly. Quick demo?              48\n",
       "11  Hello, I'm Marcus from AutoFleet Management, a...             417\n",
       "12  Zero‚Äëcapex solar: ROI 4‚Äì5 yrs, big carbon cuts...              54\n",
       "13  Hi, We optimize e-commerce shipping and fulfil...             245\n",
       "14     Organic produce <24h from harvest. Sample box?              46\n",
       "15  Hi, BuildPro reduces project delays by 35% thr...             223\n",
       "16  Predictive maintenance: 25% less downtime in 6...              60\n",
       "17  Hi, Saw your LinkedIn campaign. Our AI ad plat...             177\n",
       "18  Influencer matching: 5√ó engagement at 60% lowe...              62\n",
       "19  Dear Legal Operations Manager, I'm reaching ou...             431\n",
       "20      Hotel tech boosts reviews +23%. 15‚Äëmin intro?              45\n",
       "21  Hello, Our predictive maintenance systems redu...             226\n",
       "22  AI ads: 3‚Äì4x ROAS for brands like yours. Case ...              52\n",
       "23  Good morning, Our interactive learning platfor...             256\n",
       "24  Free ransomware security audit for financial o...              62\n",
       "25  Dear Practice Manager, I'm reaching out from M...             423\n",
       "26  Contract review 60% faster with AI. Extended t...              51\n",
       "27  Good afternoon, Our regulatory compliance soft...             274\n",
       "28  Retail foot traffic analytics lift conversions...              60\n",
       "29  Hi, Our integrated tenant portal reduces maint...             227\n",
       "30  Quote time: hours ‚Üí minutes for agencies. Expl...              50\n",
       "31  Tenant portal halves maintenance response time...              55\n",
       "32  Dear Chief Marketing Officer, I noticed your b...             457\n",
       "33  Fleet telematics can save ‚âà$85K annually. Brie...              53\n",
       "34  Compliance software trims FDA timelines 20%. L...              56\n",
       "35  BuildPro cuts delays 35% via real‚Äëtime schedul...              56\n",
       "36  Hello, With the recent increase in ransomware ...             441\n",
       "37  Hi, GreenEnergy Solutions offers industrial so...             216"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8bfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìò Step 3A ‚Äî Load Base Model & Tokenize Dataset\n",
    "# ============================================\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "def load_base_model(model_name=\"distilgpt2\"):\n",
    "    \"\"\"\n",
    "    Load the base causal language model and tokenizer.\n",
    "    Uses GPU if available.\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Loading base model: {model_name}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"‚úÖ Model loaded on: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def tokenize_seller_dataset(df, tokenizer, max_length=256):\n",
    "    \"\"\"\n",
    "    Tokenize the seller email dataset for RL training.\n",
    "    Converts each email into input_ids and attention masks.\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Tokenizing seller emails...\")\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    def tokenize_fn(example):\n",
    "        return tokenizer(\n",
    "            example[\"email_text\"],\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "    tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "    print(f\"‚úÖ Tokenized {len(tokenized_dataset)} samples\")\n",
    "    return tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8a8c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Loading base model: distilgpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\envs\\rl_ft_gpu\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded on: cuda\n",
      "üîÑ Tokenizing seller emails...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eb806955bb4a80b74ff6d6eb872688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/38 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenized 38 samples\n",
      "\n",
      "üìù Example Tokenized Sample:\n",
      "Input IDs: tensor([23286,  1098,  9744,   540, 16846,    25,  2793, 24713,    11,   976,\n",
      "         1575,    13, 12167,    30, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])\n",
      "Decoded text: Biodegradable packaging: lower footprint, same cost. Talk?\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# üìò Step 3B ‚Äî Execute Model & Tokenizer Setup\n",
    "# ============================================\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "\n",
    "model, tokenizer = load_base_model(MODEL_NAME)\n",
    "tokenized_seller_dataset = tokenize_seller_dataset(df_seller, tokenizer)\n",
    "\n",
    "# Inspect one sample\n",
    "sample = tokenized_seller_dataset[0]\n",
    "print(\"\\nüìù Example Tokenized Sample:\")\n",
    "print(\"Input IDs:\", sample[\"input_ids\"][:40])\n",
    "print(\"Decoded text:\", tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True)[:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a857956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üß© Step 4A ‚Äî Define PPO Model and Trainer Functions\n",
    "# ============================================\n",
    "import torch\n",
    "from trl import AutoModelForCausalLMWithValueHead, PPOTrainer, PPOConfig\n",
    "\n",
    "def prepare_model_for_ppo(base_model_name: str):\n",
    "    \"\"\"\n",
    "    Load a pretrained causal LM and wrap it with a value head for PPO training.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"üß© Loading and wrapping '{base_model_name}' on {device}...\")\n",
    "\n",
    "    ppo_model = AutoModelForCausalLMWithValueHead.from_pretrained(base_model_name)\n",
    "    ppo_model = ppo_model.to(device)\n",
    "\n",
    "    print(\"‚úÖ PPO-ready model created.\")\n",
    "    return ppo_model\n",
    "\n",
    "\n",
    "def create_ppo_trainer(model, tokenizer, learning_rate=1e-5, batch_size=2, log_with=None):\n",
    "    \"\"\"\n",
    "    Initialize PPO Trainer with config.\n",
    "    \"\"\"\n",
    "    print(\"‚öôÔ∏è Initializing PPO Trainer...\")\n",
    "    config = PPOConfig(\n",
    "        model_name=None,  # already loaded\n",
    "        learning_rate=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        mini_batch_size=batch_size,\n",
    "        optimize_cuda_cache=True,\n",
    "        log_with=log_with\n",
    "    )\n",
    "    trainer = PPOTrainer(config=config, model=model, tokenizer=tokenizer)\n",
    "    print(\"‚úÖ PPO Trainer initialized.\")\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8c5974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß© Loading and wrapping 'distilgpt2' on cuda...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\envs\\rl_ft_gpu\\Lib\\site-packages\\trl\\models\\modeling_base.py:331: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = loading_func(filename if not use_safe else safe_filename, **load_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PPO-ready model created.\n",
      "‚öôÔ∏è Initializing PPO Trainer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\envs\\rl_ft_gpu\\Lib\\site-packages\\trl\\trainer\\ppo_trainer.py:266: UserWarning: No dataset is provided. Make sure to set config.batch_size to the correct value before training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PPO Trainer initialized.\n",
      "\n",
      "‚úÖ Model and PPO Trainer are ready for fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ‚öôÔ∏è Step 4B ‚Äî Execute PPO Setup\n",
    "# ============================================\n",
    "\n",
    "MODEL_NAME = \"distilgpt2\"\n",
    "learning_rate = 1e-5\n",
    "batch_size = 2\n",
    "\n",
    "ppo_model = prepare_model_for_ppo(MODEL_NAME)\n",
    "ppo_trainer = create_ppo_trainer(ppo_model, tokenizer, learning_rate=learning_rate, batch_size=batch_size)\n",
    "\n",
    "print(\"\\n‚úÖ Model and PPO Trainer are ready for fine-tuning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de19e812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email_text</th>\n",
       "      <th>len_email_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biodegradable packaging: lower footprint, same...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear HR Director, I'm Jennifer from HealthFirs...</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning platform lifts test scores 18%. Pilot?</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello, I work with boutique hotels to enhance ...</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cut cloud spend 30‚Äì40%. 15‚Äëmin chat next week?...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          email_text  len_email_text\n",
       "0  Biodegradable packaging: lower footprint, same...              58\n",
       "1  Dear HR Director, I'm Jennifer from HealthFirs...             478\n",
       "2    Learning platform lifts test scores 18%. Pilot?              47\n",
       "3  Hello, I work with boutique hotels to enhance ...             432\n",
       "4  Cut cloud spend 30‚Äì40%. 15‚Äëmin chat next week?...              57"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seller.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ba502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üß© Step 5A ‚Äî Reward Modeling Functions (Fully Explained)\n",
    "# ============================================\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_sentiment_analyzer(use_gpu=True):\n",
    "    \"\"\"\n",
    "    Load sentiment analyzer (DistilBERT fine-tuned on SST-2).\n",
    "    \"\"\"\n",
    "    device = 0 if use_gpu and torch.cuda.is_available() else -1\n",
    "    print(f\"üîç Loading sentiment analyzer on {'GPU' if device == 0 else 'CPU'}...\")\n",
    "    analyzer = pipeline(\"sentiment-analysis\",\n",
    "                        model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "                        device=device)\n",
    "    return analyzer\n",
    "\n",
    "def has_cta_phrase(txt):\n",
    "    \"\"\"\n",
    "    Detect CTA (Call-to-Action) phrases in text.\n",
    "    Returns (bool, list_of_matched_phrases)\n",
    "    \"\"\"\n",
    "    txt_lower = txt.lower()\n",
    "    \n",
    "    # Define CTAs (mix of single and multiword)\n",
    "    cta_phrases = [\n",
    "        \"call\", \"reply\", \"schedule\", \"meet\",\n",
    "        \"connect\", \"reach out\", \"get in touch\", \"book a demo\",\n",
    "        \"set up a meeting\", \"schedule a call\", \"contact us\"\n",
    "    ]\n",
    "    \n",
    "    matched_phrases = []\n",
    "\n",
    "    for phrase in cta_phrases:\n",
    "        # Handle multiword phrases directly\n",
    "        if \" \" in phrase:\n",
    "            if phrase in txt_lower:\n",
    "                matched_phrases.append(phrase)\n",
    "        else:\n",
    "            # Match whole word only (e.g., \"call\" ‚â† \"calling\")\n",
    "            if re.search(rf\"\\b{re.escape(phrase)}\\b\", txt_lower):\n",
    "                matched_phrases.append(phrase)\n",
    "\n",
    "    has_match = len(matched_phrases) > 0\n",
    "    return has_match, matched_phrases\n",
    "\n",
    "def compute_reward(text: str, sentiment_analyzer=None, tool=None, weights=None, detailed=False):\n",
    "    \"\"\"\n",
    "    Compute and explain the reward breakdown for a given email.\n",
    "    Categories:\n",
    "      1. Length Reward\n",
    "      2. Politeness Reward\n",
    "      3. Sentiment Reward\n",
    "      4. Clarity\n",
    "      5. CTA (Call-to-Action)\n",
    "      6. Personalization\n",
    "      7. Grammar\n",
    "      8. Value Proposition\n",
    "      9. Spam Avoidance\n",
    "      10. Structure\n",
    "    \"\"\"\n",
    "    txt = (text or \"\").strip()\n",
    "    txt_lower = txt.lower()\n",
    "    weights = weights or {\"length\": 1.0, \"politeness\": 1.0, \"sentiment\": 1.0}\n",
    "\n",
    "    # --- 1Ô∏è‚É£ Length ---\n",
    "    length = len(txt)\n",
    "    if 100 <= length <= 300:\n",
    "        length_r = 1.0\n",
    "        length_reason = f\"‚úÖ Ideal length ({length} chars between 100‚Äì300).\"\n",
    "    elif length > 300 and length <= 450:\n",
    "        length_r = 0.2\n",
    "        length_reason = f\"‚ö†Ô∏è Slightly long ({length} chars > 300).\"\n",
    "    elif length > 450:\n",
    "        length_r = -0.7\n",
    "        length_reason = f\"‚ö†Ô∏è Too long ({length} chars > 450).\"\n",
    "    else:\n",
    "        length_r = -0.7\n",
    "        length_reason = f\"‚ö†Ô∏è Too short ({length} chars < 100).\"\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Politeness ---\n",
    "    polite_terms = [\"thank\", \"appreciate\", \"please\", \"hope\", \"kindly\", \"regards\", \"grateful\", \"welcome\", \"would you\", \"could you\"]\n",
    "    found_terms = [term for term in polite_terms if re.search(rf\"\\b{term}\\b\", txt_lower)]\n",
    "    polite_r = 0.5 * len(found_terms)\n",
    "    if len(found_terms) > 0:\n",
    "        polite_reason = f\"‚úÖ Found polite terms: {', '.join(found_terms)} (+{polite_r:.1f}).\"\n",
    "    else:\n",
    "        polite_reason = \"‚ö†Ô∏è No polite words detected.\"\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Sentiment ---\n",
    "    sentiment_r = 0.0\n",
    "    sentiment_reason = \"\"\n",
    "    if sentiment_analyzer is not None:\n",
    "        try:\n",
    "            out = sentiment_analyzer(txt[:512])\n",
    "            if out and isinstance(out, list) and \"label\" in out[0]:\n",
    "                label = out[0][\"label\"].upper()\n",
    "                score = out[0].get(\"score\", 0)\n",
    "                if label.startswith(\"POS\"):\n",
    "                    sentiment_r = 1.0\n",
    "                    sentiment_reason = f\"‚úÖ Positive tone detected (score={score:.2f}).\"\n",
    "                elif label.startswith(\"NEG\"):\n",
    "                    sentiment_r = -0.3\n",
    "                    sentiment_reason = f\"‚ö†Ô∏è Negative tone detected (score={score:.2f}).\"\n",
    "                else:\n",
    "                    sentiment_reason = f\"üòê Neutral tone detected (score={score:.2f}).\"\n",
    "        except Exception as e:\n",
    "            sentiment_reason = f\"‚ö†Ô∏è Sentiment analysis failed: {e}\"\n",
    "            sentiment_r = 0.0\n",
    "\n",
    "    # --- 4Ô∏è‚É£ Clarity ---\n",
    "    unclear_terms = [\"utilize\", \"leverage\", \"synergy\", \"paradigm\", \"bandwidth\", \"ecosystem\", \"turnkey\", \"disruptive\"]\n",
    "    found_terms = [term for term in unclear_terms if re.search(rf\"\\b{term}\\b\", txt_lower)]\n",
    "    clarity_r = -0.3 * len(found_terms) if found_terms else 0.7\n",
    "    clarity_reason = f\"‚ö†Ô∏è Found unclear terms: {', '.join(found_terms)}\" if found_terms else \"‚úÖ Clear and simple language.\"\n",
    "\n",
    "    # --- 5Ô∏è‚É£ CTA (Call-to-Action) ---\n",
    "    cta_phrases = [\"schedule a call\", \"book a demo\", \"let‚Äôs connect\", \"reply\", \"meet\", \"call\", \"let me know\", \"get started\", \"sign up\", \"try it now\"]\n",
    "    has_cta = any(p in txt_lower for p in cta_phrases)\n",
    "    #has_cta = has_cta_phrase(txt)\n",
    "    has_cta, matched_ctas = has_cta_phrase(txt)\n",
    "    cta_r = 1.0 if has_cta else -0.8\n",
    "    cta_reason = \"‚úÖ Contains clear call-to-action words like \" + \", \".join(matched_ctas) if has_cta else \"‚ö†Ô∏è No clear call-to-action.\"\n",
    "\n",
    "    # --- 6Ô∏è‚É£ Personalization ---\n",
    "    personalization_terms = [\"you\", \"your team\", \"your company\", \"dear\", \"hello\"]\n",
    "    personalized = any(t in txt_lower for t in personalization_terms)\n",
    "    personalization_r = 0.7 if personalized else -0.2\n",
    "    personalization_reason = \"‚úÖ Personalized tone with terms like \" + \", \".join([t for t in personalization_terms if t in txt_lower]) if personalized else \"‚ö†Ô∏è No personalization detected.\"\n",
    "\n",
    "    # --- 7Ô∏è‚É£ Grammar ---\n",
    "    grammar_r, grammar_reason = 0.0, \"\"\n",
    "    if tool is not None:\n",
    "        try:\n",
    "            correction = tool.check(txt)\n",
    "            n_errors = len(correction)\n",
    "            if n_errors == 0:\n",
    "                grammar_r = 1.0\n",
    "                grammar_reason = \"‚úÖ No grammatical errors detected.\"\n",
    "            elif n_errors < 4:\n",
    "                grammar_r = 0.5\n",
    "                grammar_reason = f\"‚ö†Ô∏è Few grammatical errors detected ({n_errors} issues).\"\n",
    "            else:\n",
    "                grammar_r = -0.3\n",
    "                grammar_reason = f\"‚ùå Many grammatical errors detected ({n_errors} issues).\"\n",
    "        except Exception as e:\n",
    "            grammar_reason = f\"‚ö†Ô∏è Grammar check failed: {e}\"\n",
    "            grammar_r = 0.0\n",
    "\n",
    "    # --- 8Ô∏è‚É£ Value Proposition ---\n",
    "    value_terms = re.findall(r\"\\b(save|reduce|increase|boost|improve|growth|roi|cost|revenue|profit)\\b\", txt, re.I)\n",
    "    value_r = min(len(value_terms) * 0.5, 1.0)\n",
    "    value_reason = f\"‚úÖ Value terms found: {', '.join(set(value_terms))}.\" if value_terms else \"‚ö†Ô∏è No value proposition terms.\"\n",
    "\n",
    "    # --- 9Ô∏è‚É£ Spam Avoidance ---\n",
    "    spam_terms = [\"free\", \"winner\", \"click here\", \"urgent\", \"act now\", \"limited time\", \"guarantee\"]\n",
    "    found_spam = [term for term in spam_terms if re.search(rf\"\\b{term}\\b\", txt_lower)]\n",
    "    spam_r = -0.8 * len(found_spam) if found_spam else 0.5\n",
    "    spam_reason = f\"‚ùå Spammy terms found: {', '.join(found_spam)}.\" if found_spam else \"‚úÖ No spammy terms detected.\"\n",
    "\n",
    "    # --- üîü Structure ---\n",
    "    has_greeting = bool(re.search(r\"\\b(dear|hi|hello|greetings|to whom it may concern)\\b\", txt_lower))\n",
    "    has_closing = bool(re.search(r\"(regards|sincerely|best)\", txt_lower))\n",
    "    if has_greeting and has_closing:\n",
    "        structure_r, structure_reason = 1.0, \"‚úÖ Proper greeting and closing.\"\n",
    "    elif has_greeting or has_closing:\n",
    "        structure_r, structure_reason = 0.5, \"‚ö†Ô∏è Missing either greeting or closing.\"\n",
    "    else:\n",
    "        structure_r, structure_reason = -0.5, \"‚ö†Ô∏è Missing both greeting and closing.\"\n",
    "\n",
    "    # --- Weighted total ---\n",
    "    total_reward = (\n",
    "        weights[\"length\"] * length_r\n",
    "        + weights[\"politeness\"] * polite_r\n",
    "        + weights[\"sentiment\"] * sentiment_r\n",
    "        + weights[\"clarity\"] * clarity_r\n",
    "        + weights[\"cta\"] * cta_r\n",
    "        + weights[\"personalization\"] * personalization_r\n",
    "        + weights[\"grammar\"] * grammar_r\n",
    "        + weights[\"value\"] * value_r\n",
    "        + weights[\"spam\"] * spam_r\n",
    "        + weights[\"structure\"] * structure_r\n",
    "    )\n",
    "    \n",
    "    print(f\"total_reward before clipping: {total_reward}\")\n",
    "    total_reward = float(np.clip(total_reward, -4.0, 6.0))\n",
    "    print(f\"total_reward after clipping: {total_reward}\")\n",
    "\n",
    "    if detailed:\n",
    "        return total_reward, {\n",
    "            \"length\": length_r,\n",
    "            \"politeness\": polite_r,\n",
    "            \"sentiment\": sentiment_r,\n",
    "            \"clarity\": clarity_r,\n",
    "            \"cta\": cta_r,\n",
    "            \"personalization\": personalization_r,\n",
    "            \"grammar\": grammar_r,\n",
    "            \"value\": value_r,\n",
    "            \"spam\": spam_r,\n",
    "            \"structure\": structure_r,\n",
    "            \"reasons\": {\n",
    "                \"length\": length_reason,\n",
    "                \"politeness\": polite_reason,\n",
    "                \"sentiment\": sentiment_reason,\n",
    "                \"clarity\": clarity_reason,\n",
    "                \"cta\": cta_reason,\n",
    "                \"personalization\": personalization_reason,\n",
    "                \"grammar\": grammar_reason,\n",
    "                \"value\": value_reason,\n",
    "                \"spam\": spam_reason,\n",
    "                \"structure\": structure_reason\n",
    "            }\n",
    "        }\n",
    "    return total_reward\n",
    "\n",
    "\n",
    "def test_reward_function(df, reward_fn, n_samples=3, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluate reward on sample seller emails with complete reasoning.\n",
    "    \"\"\"\n",
    "    print(\"\\nüßÆ Testing Reward Function with Explanations:\\n\")\n",
    "    sample_emails = df[\"email_text\"].sample(n_samples, random_state=42)\n",
    "\n",
    "    weights = kwargs.get(\"weights\", {\"length\": 1.0, \"politeness\": 1.0, \"sentiment\": 1.0, \"clarity\":1.0, \"cta\":1.0, \"personalization\":1.0, \"grammar\":1.0, \"value\":1.0, \"spam\":1.0, \"structure\":1.0})\n",
    "\n",
    "    for i, email in enumerate(sample_emails, 1):\n",
    "        \n",
    "        print(f\"üìß Email #{i}\")\n",
    "        print(f\"Excerpt: {email[:180]}...\\n\")\n",
    "        \n",
    "        total, breakdown = reward_fn(email, detailed=True, **kwargs)\n",
    "        reasons = breakdown[\"reasons\"]\n",
    "\n",
    "        print(\"üßæ Reward Components & Explanations:\")\n",
    "        print(f\"  ‚îú‚îÄ Length Reward:     {breakdown['length']:+.2f} - {reasons['length']}\")\n",
    "        print(f\"  ‚îú‚îÄ Politeness Reward: {breakdown['politeness']:+.2f} - {reasons['politeness']}\")\n",
    "        print(f\"  ‚îî‚îÄ Sentiment Reward:  {breakdown['sentiment']:+.2f} - {reasons['sentiment']}\")\n",
    "        print(f\"  ‚îú‚îÄ Clarity Reward:    {breakdown['clarity']:+.2f} - {reasons['clarity']}\")\n",
    "        print(f\"  ‚îú‚îÄ CTA Reward:        {breakdown['cta']:+.2f} - {reasons['cta']}\")\n",
    "        print(f\"  ‚îú‚îÄ Personalization:   {breakdown['personalization']:+.2f} - {reasons['personalization']}\")\n",
    "        print(f\"  ‚îú‚îÄ Grammar Reward:    {breakdown['grammar']:+.2f} - {reasons['grammar']}\")\n",
    "        print(f\"  ‚îú‚îÄ Value Prop Reward: {breakdown['value']:+.2f} - {reasons['value']}\")\n",
    "        print(f\"  ‚îú‚îÄ Spam Avoidance:    {breakdown['spam']:+.2f} - {reasons['spam']}\")\n",
    "        print(f\"  ‚îî‚îÄ Structure Reward:  {breakdown['structure']:+.2f} - {reasons['structure']}\")\n",
    "        print(f\"  ‚Ä¢ Weights Used:      {weights}\")\n",
    "\n",
    "        # Explicit calculation formula\n",
    "        calc_str = (\n",
    "            f\"({weights['length']}√ó{breakdown['length']:.2f}) + \"\n",
    "            f\"({weights['politeness']}√ó{breakdown['politeness']:.2f}) + \"\n",
    "            f\"({weights['sentiment']}√ó{breakdown['sentiment']:.2f}) + \"\n",
    "            f\"({weights['clarity']}√ó{breakdown['clarity']:.2f}) + \"\n",
    "            f\"({weights['cta']}√ó{breakdown['cta']:.2f}) + \"\n",
    "            f\"({weights['personalization']}√ó{breakdown['personalization']:.2f}) + \"\n",
    "            f\"({weights['grammar']}√ó{breakdown['grammar']:.2f}) + \"\n",
    "            f\"({weights['value']}√ó{breakdown['value']:.2f}) + \"\n",
    "            f\"({weights['spam']}√ó{breakdown['spam']:.2f}) + \"\n",
    "            f\"({weights['structure']}√ó{breakdown['structure']:.2f})\"\n",
    "        )\n",
    "        intermediate_sum = (\n",
    "            weights[\"length\"] * breakdown[\"length\"]\n",
    "            + weights[\"politeness\"] * breakdown[\"politeness\"]\n",
    "            + weights[\"sentiment\"] * breakdown[\"sentiment\"]\n",
    "            + weights[\"clarity\"] * breakdown[\"clarity\"]\n",
    "            + weights[\"cta\"] * breakdown[\"cta\"]\n",
    "            + weights[\"personalization\"] * breakdown[\"personalization\"]\n",
    "            + weights[\"grammar\"] * breakdown[\"grammar\"]\n",
    "            + weights[\"value\"] * breakdown[\"value\"]\n",
    "            + weights[\"spam\"] * breakdown[\"spam\"]\n",
    "            + weights[\"structure\"] * breakdown[\"structure\"]\n",
    "        )\n",
    "\n",
    "        print(\"\\nüßÆ Calculation:\")\n",
    "        print(f\"  = {calc_str}\")\n",
    "        print(f\"  = {intermediate_sum:.2f}\")\n",
    "        print(f\"  ‚Üí Final Clipped Reward: {total:.2f}\")\n",
    "        print(\"-\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51930ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßÆ Testing Reward Function with Explanations:\n",
      "\n",
      "total_reward before clipping: 1.98\n",
      "total_reward after clipping: 1.98\n",
      "üìß Email #1\n",
      "Excerpt: Fleet telematics can save ‚âà$85K annually. Brief call?...\n",
      "\n",
      "üßæ Reward Components & Explanations:\n",
      "  ‚îú‚îÄ Length Reward:     -0.70 - ‚ö†Ô∏è Too short (53 chars < 100).\n",
      "  ‚îú‚îÄ Politeness Reward: +0.00 - ‚ö†Ô∏è No polite words detected.\n",
      "  ‚îî‚îÄ Sentiment Reward:  -0.30 - ‚ö†Ô∏è Negative tone detected (score=1.00).\n",
      "  ‚îú‚îÄ Clarity Reward:    +0.70 - ‚úÖ Clear and simple language.\n",
      "  ‚îú‚îÄ CTA Reward:        +1.00 - ‚úÖ Contains clear call-to-action words like call\n",
      "  ‚îú‚îÄ Personalization:   -0.20 - ‚ö†Ô∏è No personalization detected.\n",
      "  ‚îú‚îÄ Grammar Reward:    +1.00 - ‚úÖ No grammatical errors detected.\n",
      "  ‚îú‚îÄ Value Prop Reward: +0.50 - ‚úÖ Value terms found: save.\n",
      "  ‚îú‚îÄ Spam Avoidance:    +0.50 - ‚úÖ No spammy terms detected.\n",
      "  ‚îî‚îÄ Structure Reward:  -0.50 - ‚ö†Ô∏è Missing both greeting and closing.\n",
      "  ‚Ä¢ Weights Used:      {'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n",
      "\n",
      "üßÆ Calculation:\n",
      "  = (1.2√ó-0.70) + (1.2√ó0.00) + (0.7√ó-0.30) + (0.6√ó0.70) + (1.4√ó1.00) + (0.7√ó-0.20) + (0.8√ó1.00) + (1.1√ó0.50) + (0.8√ó0.50) + (0.8√ó-0.50)\n",
      "  = 1.98\n",
      "  ‚Üí Final Clipped Reward: 1.98\n",
      "----------------------------------------------------------------------\n",
      "total_reward before clipping: 5.0\n",
      "total_reward after clipping: 5.0\n",
      "üìß Email #2\n",
      "Excerpt: Hello, With the recent increase in ransomware attacks targeting financial services, I wanted to reach out and offer a complimentary security audit for your organization. SecureNet ...\n",
      "\n",
      "üßæ Reward Components & Explanations:\n",
      "  ‚îú‚îÄ Length Reward:     +0.20 - ‚ö†Ô∏è Slightly long (437 chars > 300).\n",
      "  ‚îú‚îÄ Politeness Reward: +0.00 - ‚ö†Ô∏è No polite words detected.\n",
      "  ‚îî‚îÄ Sentiment Reward:  +1.00 - ‚úÖ Positive tone detected (score=0.99).\n",
      "  ‚îú‚îÄ Clarity Reward:    +0.70 - ‚úÖ Clear and simple language.\n",
      "  ‚îú‚îÄ CTA Reward:        +1.00 - ‚úÖ Contains clear call-to-action words like call\n",
      "  ‚îú‚îÄ Personalization:   +0.70 - ‚úÖ Personalized tone with terms like you, hello\n",
      "  ‚îú‚îÄ Grammar Reward:    +0.50 - ‚ö†Ô∏è Few grammatical errors detected (2 issues).\n",
      "  ‚îú‚îÄ Value Prop Reward: +0.50 - ‚úÖ Value terms found: increase.\n",
      "  ‚îú‚îÄ Spam Avoidance:    +0.50 - ‚úÖ No spammy terms detected.\n",
      "  ‚îî‚îÄ Structure Reward:  +0.50 - ‚ö†Ô∏è Missing either greeting or closing.\n",
      "  ‚Ä¢ Weights Used:      {'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n",
      "\n",
      "üßÆ Calculation:\n",
      "  = (1.2√ó0.20) + (1.2√ó0.00) + (0.7√ó1.00) + (0.6√ó0.70) + (1.4√ó1.00) + (0.7√ó0.70) + (0.8√ó0.50) + (1.1√ó0.50) + (0.8√ó0.50) + (0.8√ó0.50)\n",
      "  = 5.00\n",
      "  ‚Üí Final Clipped Reward: 5.00\n",
      "----------------------------------------------------------------------\n",
      "total_reward before clipping: -1.4899999999999998\n",
      "total_reward after clipping: -1.4899999999999998\n",
      "üìß Email #3\n",
      "Excerpt: Cut cloud spend 30‚Äì40%. 15‚Äëmin chat next week? ‚Äì DataSync...\n",
      "\n",
      "üßæ Reward Components & Explanations:\n",
      "  ‚îú‚îÄ Length Reward:     -0.70 - ‚ö†Ô∏è Too short (57 chars < 100).\n",
      "  ‚îú‚îÄ Politeness Reward: +0.00 - ‚ö†Ô∏è No polite words detected.\n",
      "  ‚îî‚îÄ Sentiment Reward:  -0.30 - ‚ö†Ô∏è Negative tone detected (score=1.00).\n",
      "  ‚îú‚îÄ Clarity Reward:    +0.70 - ‚úÖ Clear and simple language.\n",
      "  ‚îú‚îÄ CTA Reward:        -0.80 - ‚ö†Ô∏è No clear call-to-action.\n",
      "  ‚îú‚îÄ Personalization:   -0.20 - ‚ö†Ô∏è No personalization detected.\n",
      "  ‚îú‚îÄ Grammar Reward:    +0.50 - ‚ö†Ô∏è Few grammatical errors detected (1 issues).\n",
      "  ‚îú‚îÄ Value Prop Reward: +0.00 - ‚ö†Ô∏è No value proposition terms.\n",
      "  ‚îú‚îÄ Spam Avoidance:    +0.50 - ‚úÖ No spammy terms detected.\n",
      "  ‚îî‚îÄ Structure Reward:  -0.50 - ‚ö†Ô∏è Missing both greeting and closing.\n",
      "  ‚Ä¢ Weights Used:      {'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n",
      "\n",
      "üßÆ Calculation:\n",
      "  = (1.2√ó-0.70) + (1.2√ó0.00) + (0.7√ó-0.30) + (0.6√ó0.70) + (1.4√ó-0.80) + (0.7√ó-0.20) + (0.8√ó0.50) + (1.1√ó0.00) + (0.8√ó0.50) + (0.8√ó-0.50)\n",
      "  = -1.49\n",
      "  ‚Üí Final Clipped Reward: -1.49\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool latest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 254M/254M [00:52<00:00, 4.84MB/s] \n",
      "Unzipping C:\\Users\\MOIDHA~1\\AppData\\Local\\Temp\\tmpur1grx_3.zip to C:\\Users\\moidhassan\\.cache\\language_tool_python.\n",
      "Downloaded https://internal1.languagetool.org/snapshots/LanguageTool-latest-snapshot.zip to C:\\Users\\moidhassan\\.cache\\language_tool_python.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward before clipping: 6.960000000000001\n",
      "total_reward after clipping: 6.0\n",
      "üìß Email #4\n",
      "Excerpt: Hi, We optimize e-commerce shipping and fulfillment. Clients see 20-30% logistics cost reduction through our warehouse network and carrier partnerships. Brief call about your fulfi...\n",
      "\n",
      "üßæ Reward Components & Explanations:\n",
      "  ‚îú‚îÄ Length Reward:     +1.00 - ‚úÖ Ideal length (242 chars between 100‚Äì300).\n",
      "  ‚îú‚îÄ Politeness Reward: +0.50 - ‚úÖ Found polite terms: regards (+0.5).\n",
      "  ‚îî‚îÄ Sentiment Reward:  +1.00 - ‚úÖ Positive tone detected (score=0.85).\n",
      "  ‚îú‚îÄ Clarity Reward:    +0.70 - ‚úÖ Clear and simple language.\n",
      "  ‚îú‚îÄ CTA Reward:        +1.00 - ‚úÖ Contains clear call-to-action words like call\n",
      "  ‚îú‚îÄ Personalization:   +0.70 - ‚úÖ Personalized tone with terms like you\n",
      "  ‚îú‚îÄ Grammar Reward:    +0.50 - ‚ö†Ô∏è Few grammatical errors detected (1 issues).\n",
      "  ‚îú‚îÄ Value Prop Reward: +0.50 - ‚úÖ Value terms found: cost.\n",
      "  ‚îú‚îÄ Spam Avoidance:    +0.50 - ‚úÖ No spammy terms detected.\n",
      "  ‚îî‚îÄ Structure Reward:  +1.00 - ‚úÖ Proper greeting and closing.\n",
      "  ‚Ä¢ Weights Used:      {'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n",
      "\n",
      "üßÆ Calculation:\n",
      "  = (1.2√ó1.00) + (1.2√ó0.50) + (0.7√ó1.00) + (0.6√ó0.70) + (1.4√ó1.00) + (0.7√ó0.70) + (0.8√ó0.50) + (1.1√ó0.50) + (0.8√ó0.50) + (0.8√ó1.00)\n",
      "  = 6.96\n",
      "  ‚Üí Final Clipped Reward: 6.00\n",
      "----------------------------------------------------------------------\n",
      "total_reward before clipping: -1.0899999999999999\n",
      "total_reward after clipping: -1.0899999999999999\n",
      "üìß Email #5\n",
      "Excerpt: Quote time: hours ‚Üí minutes for agencies. Explore?...\n",
      "\n",
      "üßæ Reward Components & Explanations:\n",
      "  ‚îú‚îÄ Length Reward:     -0.70 - ‚ö†Ô∏è Too short (50 chars < 100).\n",
      "  ‚îú‚îÄ Politeness Reward: +0.00 - ‚ö†Ô∏è No polite words detected.\n",
      "  ‚îî‚îÄ Sentiment Reward:  -0.30 - ‚ö†Ô∏è Negative tone detected (score=0.97).\n",
      "  ‚îú‚îÄ Clarity Reward:    +0.70 - ‚úÖ Clear and simple language.\n",
      "  ‚îú‚îÄ CTA Reward:        -0.80 - ‚ö†Ô∏è No clear call-to-action.\n",
      "  ‚îú‚îÄ Personalization:   -0.20 - ‚ö†Ô∏è No personalization detected.\n",
      "  ‚îú‚îÄ Grammar Reward:    +1.00 - ‚úÖ No grammatical errors detected.\n",
      "  ‚îú‚îÄ Value Prop Reward: +0.00 - ‚ö†Ô∏è No value proposition terms.\n",
      "  ‚îú‚îÄ Spam Avoidance:    +0.50 - ‚úÖ No spammy terms detected.\n",
      "  ‚îî‚îÄ Structure Reward:  -0.50 - ‚ö†Ô∏è Missing both greeting and closing.\n",
      "  ‚Ä¢ Weights Used:      {'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n",
      "\n",
      "üßÆ Calculation:\n",
      "  = (1.2√ó-0.70) + (1.2√ó0.00) + (0.7√ó-0.30) + (0.6√ó0.70) + (1.4√ó-0.80) + (0.7√ó-0.20) + (0.8√ó1.00) + (1.1√ó0.00) + (0.8√ó0.50) + (0.8√ó-0.50)\n",
      "  = -1.09\n",
      "  ‚Üí Final Clipped Reward: -1.09\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ‚öôÔ∏è Step 5B ‚Äî Run Reward Evaluation (Extended)\n",
    "# ============================================\n",
    "from language_tool_python import LanguageTool\n",
    "\n",
    "# ‚úÖ Load sentiment model once (cached)\n",
    "if \"sentiment_analyzer\" not in globals():\n",
    "    sentiment_analyzer = load_sentiment_analyzer(use_gpu=True)\n",
    "\n",
    "# ‚úÖ Load LanguageTool only once (cached)\n",
    "if \"tool\" not in globals():\n",
    "    print(\"üß† Initializing LanguageTool (cached once)...\")\n",
    "    tool = LanguageTool('en-US')\n",
    "\n",
    "# Define reward weights\n",
    "reward_weights = {\n",
    "    \"length\": 1.2,\n",
    "    \"politeness\": 1.2,\n",
    "    \"sentiment\": 0.7,\n",
    "    \"clarity\": 0.6,\n",
    "    \"cta\": 1.4,\n",
    "    \"personalization\": 0.7,\n",
    "    \"grammar\": 0.8,\n",
    "    \"value\": 1.1,\n",
    "    \"spam\": 0.8,\n",
    "    \"structure\": 0.8\n",
    "}\n",
    "# Evaluate on sample emails (now with extended components and explanations)\n",
    "test_reward_function(\n",
    "    df_seller,\n",
    "    compute_reward,\n",
    "    n_samples=5,\n",
    "    sentiment_analyzer=sentiment_analyzer,\n",
    "    tool=tool,\n",
    "    weights=reward_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7db74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üß© Step 6A ‚Äî RL Environment for Email Task\n",
    "# ============================================\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import random\n",
    "\n",
    "class EmailEnv:\n",
    "    \"\"\"\n",
    "    Minimal RL environment for email generation.\n",
    "    The model generates an email ‚Üí we compute its reward.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"gpt2\", sentiment_analyzer=None, tool=None, weights=None):\n",
    "        print(f\"üöÄ Initializing model: {model_name}\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.sentiment_analyzer = sentiment_analyzer\n",
    "        self.tool = tool\n",
    "        self.weights = weights or {}\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def generate_email(self, prompt, max_new_tokens=150, temperature=0.7):\n",
    "        \"\"\"\n",
    "        Generate a sample email given a short prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return generated\n",
    "\n",
    "    def compute_reward(self, email_text):\n",
    "        \"\"\"\n",
    "        Compute reward for a generated email.\n",
    "        \"\"\"\n",
    "        total, details = compute_reward(\n",
    "            email_text,\n",
    "            detailed=True,\n",
    "            sentiment_analyzer=self.sentiment_analyzer,\n",
    "            tool=self.tool,\n",
    "            weights=self.weights\n",
    "        )\n",
    "        return total, details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b21682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'length': 1.2, 'politeness': 1.2, 'sentiment': 0.7, 'clarity': 0.6, 'cta': 1.4, 'personalization': 0.7, 'grammar': 0.8, 'value': 1.1, 'spam': 0.8, 'structure': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(reward_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30358c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing model: gpt2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moidhassan\\AppData\\Local\\anaconda3\\envs\\rl_ft_gpu\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward before clipping: 3.3699999999999997\n",
      "total_reward after clipping: 3.3699999999999997\n",
      "\n",
      "üìß Generated Email:\n",
      " Write a professional email to introduce a new Surface device to a potential enterprise buyer.\n",
      "\n",
      "1. Choose a Product\n",
      "\n",
      "If you are an enterprise user, you will be able to purchase a Surface Pro 3. The Surface Pro 3 is the best choice. The price of the Surface Pro 3 is around $200. The Pro 3 is a tablet-friendly device (and the easiest to use). It has a built-in keyboard, and it's built-in camera.\n",
      "\n",
      "The Surface Pro 3 is also a great choice for businesses looking to have a full-sized tablet. Many companies use the Surface Pro 3 as a desktop environment. They have large, powerful screens and the Pro 3 comes with a built-in camera with a built-in video and audio recorder.\n",
      "\n",
      "2. Choose a Product\n",
      "\n",
      "\n",
      "\n",
      "üèÜ Reward: 3.3699999999999997\n",
      "Breakdown: {'length': -0.7, 'politeness': 0.0, 'sentiment': 1.0, 'clarity': 0.7, 'cta': 1.0, 'personalization': 0.7, 'grammar': 0.5, 'value': 0.0, 'spam': 0.5, 'structure': 0.5, 'reasons': {'length': '‚ö†Ô∏è Too long (692 chars > 450).', 'politeness': '‚ö†Ô∏è No polite words detected.', 'sentiment': '‚úÖ Positive tone detected (score=0.99).', 'clarity': '‚úÖ Clear and simple language.', 'cta': '‚úÖ Contains clear call-to-action words like email', 'personalization': '‚úÖ Personalized tone with terms like you', 'grammar': '‚ö†Ô∏è Few grammatical errors detected (1 issues).', 'value': '‚ö†Ô∏è No value proposition terms.', 'spam': '‚úÖ No spammy terms detected.', 'structure': '‚ö†Ô∏è Missing either greeting or closing.'}}\n",
      "length: ‚ö†Ô∏è Too long (692 chars > 450).\n",
      "politeness: ‚ö†Ô∏è No polite words detected.\n",
      "sentiment: ‚úÖ Positive tone detected (score=0.99).\n",
      "clarity: ‚úÖ Clear and simple language.\n",
      "cta: ‚úÖ Contains clear call-to-action words like email\n",
      "personalization: ‚úÖ Personalized tone with terms like you\n",
      "grammar: ‚ö†Ô∏è Few grammatical errors detected (1 issues).\n",
      "value: ‚ö†Ô∏è No value proposition terms.\n",
      "spam: ‚úÖ No spammy terms detected.\n",
      "structure: ‚ö†Ô∏è Missing either greeting or closing.\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ‚öôÔ∏è Step 6B ‚Äî Test Environment + Reward\n",
    "# ============================================\n",
    "\n",
    "# Initialize environment\n",
    "env = EmailEnv(\n",
    "    model_name=\"gpt2\",\n",
    "    sentiment_analyzer=sentiment_analyzer,\n",
    "    tool=tool,\n",
    "    weights=reward_weights\n",
    ")\n",
    "\n",
    "prompt = \"Write a professional email to introduce a new Surface device to a potential enterprise buyer.\"\n",
    "generated_email = env.generate_email(prompt)\n",
    "reward, details = env.compute_reward(generated_email)\n",
    "\n",
    "print(\"\\nüìß Generated Email:\\n\", generated_email)\n",
    "print(\"\\nüèÜ Reward:\", reward)\n",
    "print(\"Breakdown:\", details)\n",
    "for key, val in details['reasons'].items():\n",
    "    print(f\"{key}: {val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a768c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL Finetune (GPU)",
   "language": "python",
   "name": "rl_ft_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
